# ãƒ¬ãƒƒã‚¹ãƒ³1: LLMã®åŸºæœ¬çš„ãªãƒãƒ£ãƒƒãƒˆæ©Ÿèƒ½

## ğŸ¯ å­¦ç¿’ç›®æ¨™
- LLMã¨ã®åŸºæœ¬çš„ãªå¯¾è©±æ–¹æ³•ã‚’ç†è§£ã™ã‚‹
- SystemMessageã¨HumanMessageã®å½¹å‰²ã‚’å­¦ã¶
- temperatureãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®åŠ¹æœã‚’ç†è§£ã™ã‚‹

## ğŸ“ ã‚¿ã‚¹ã‚¯1: ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã™ã‚‹

ã¾ãšã€`01_basic_chat.py` ã¨ã„ã†ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

## ğŸ“ ã‚¿ã‚¹ã‚¯2: å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã™ã‚‹

ä»¥ä¸‹ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ã¦ãã ã•ã„ï¼š

```python
from langchain_ollama import ChatOllama
from langchain_core.messages import HumanMessage, SystemMessage
```

**è§£èª¬:**
- `ChatOllama`: Ollamaã®ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ã†ãŸã‚ã®ã‚¯ãƒ©ã‚¹
- `HumanMessage`: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ã™ã‚¯ãƒ©ã‚¹
- `SystemMessage`: ã‚·ã‚¹ãƒ†ãƒ ï¼ˆAIã®å½¹å‰²è¨­å®šï¼‰ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ã™ã‚¯ãƒ©ã‚¹

## ğŸ“ ã‚¿ã‚¹ã‚¯3: ãƒ¢ãƒ‡ãƒ«ã‚’åˆæœŸåŒ–ã™ã‚‹

æ¬¡ã®ã‚³ãƒ¼ãƒ‰ã‚’æ›¸ã„ã¦ãã ã•ã„ï¼š

```python
llm = ChatOllama(
    model="llama3.2:1b",
    temperature=0.7
)
```

**è§£èª¬:**
- `model`: ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã®åå‰
- `temperature`: 0.0ï¼ˆæ±ºå®šçš„ï¼‰ã€œ 1.0ï¼ˆå‰µé€ çš„ï¼‰ã®ç¯„å›²ã§å¿œç­”ã®ãƒ©ãƒ³ãƒ€ãƒ æ€§ã‚’åˆ¶å¾¡

## ğŸ“ ã‚¿ã‚¹ã‚¯4: ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ä½œæˆã™ã‚‹

SystemMessageã¨HumanMessageã‚’ä½œæˆã—ã¦ãã ã•ã„ï¼š

```python
messages = [
    SystemMessage(content="You are a helpful AI assistant. Answer concisely in Japanese."),
    HumanMessage(content="LangChainã¨ã¯ä½•ã§ã™ã‹ï¼Ÿç°¡æ½”ã«èª¬æ˜ã—ã¦ãã ã•ã„ã€‚")
]
```

**è§£èª¬:**
- `SystemMessage`: AIã®æ€§æ ¼ã‚„å½¹å‰²ã‚’å®šç¾©ã—ã¾ã™
- `HumanMessage`: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã‚’å«ã¿ã¾ã™
- ã“ã®é †ç•ªã§ãƒªã‚¹ãƒˆã«å…¥ã‚Œã‚‹ã®ãŒé‡è¦ã§ã™

## ğŸ“ ã‚¿ã‚¹ã‚¯5: LLMã«å•ã„åˆã‚ã›ã‚‹

ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’LLMã«é€ä¿¡ã—ã¦ã€å¿œç­”ã‚’å—ã‘å–ã‚Šã¾ã—ã‚‡ã†ï¼š

```python
response = llm.invoke(messages)
print(response.content)
```

**è§£èª¬:**
- `invoke()`: ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é€ä¿¡ã—ã¦å¿œç­”ã‚’å—ã‘å–ã‚‹
- `response.content`: å¿œç­”ã®ãƒ†ã‚­ã‚¹ãƒˆéƒ¨åˆ†ã‚’å–å¾—

## ğŸ“ ã‚¿ã‚¹ã‚¯6: å®Ÿè¡Œã—ã¦ã¿ã‚‹

ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã§ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ï¼š

```bash
python 01_basic_chat.py
```

## âœ… ç¢ºèªãƒã‚¤ãƒ³ãƒˆ

- [ ] ãƒ•ã‚¡ã‚¤ãƒ«ãŒä½œæˆã§ãã¾ã—ãŸã‹ï¼Ÿ
- [ ] ã™ã¹ã¦ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆãŒã‚¨ãƒ©ãƒ¼ãªãå‹•ä½œã—ã¾ã—ãŸã‹ï¼Ÿ
- [ ] LLMã‹ã‚‰æ—¥æœ¬èªã§å¿œç­”ãŒè¿”ã£ã¦ãã¾ã—ãŸã‹ï¼Ÿ

## ğŸ”¬ å®Ÿé¨“: temperatureã‚’å¤‰ãˆã¦ã¿ã‚‹

ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰ã‚’è¿½åŠ ã—ã¦ã€temperatureã®é•ã„ã‚’è¦³å¯Ÿã—ã¦ãã ã•ã„ï¼š

```python
print("\n=== temperature = 0.0 (æ±ºå®šçš„) ===")
llm_low = ChatOllama(model="llama3.2:1b", temperature=0.0)
response_low = llm_low.invoke([HumanMessage(content="ã“ã‚“ã«ã¡ã¯")])
print(response_low.content)

print("\n=== temperature = 1.0 (å‰µé€ çš„) ===")
llm_high = ChatOllama(model="llama3.2:1b", temperature=1.0)
response_high = llm_high.invoke([HumanMessage(content="ã“ã‚“ã«ã¡ã¯")])
print(response_high.content)
```

åŒã˜è³ªå•ã§ä½•åº¦ã‹å®Ÿè¡Œã—ã¦ã€å¿œç­”ã®é•ã„ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚

## ğŸ’¡ ç†è§£åº¦ãƒã‚§ãƒƒã‚¯

ä»¥ä¸‹ã®è³ªå•ã«ç­”ãˆã‚‰ã‚Œã¾ã™ã‹ï¼Ÿ

1. SystemMessageã¨HumanMessageã®é•ã„ã¯ä½•ã§ã™ã‹ï¼Ÿ
2. temperatureãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯ä½•ã‚’åˆ¶å¾¡ã—ã¾ã™ã‹ï¼Ÿ
3. `invoke()`ãƒ¡ã‚½ãƒƒãƒ‰ã¯ä½•ã‚’è¿”ã—ã¾ã™ã‹ï¼Ÿ

## ğŸ‰ å®Œäº†ã—ãŸã‚‰

å®Œäº†ã—ãŸã‚‰ã€`LESSON_02.md` ã‚’é–‹ã„ã¦ãƒ¬ãƒƒã‚¹ãƒ³2ã«é€²ã‚“ã§ãã ã•ã„ï¼
